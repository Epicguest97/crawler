name: Selenium Crawler

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  selenium-crawl:
    runs-on: ubuntu-22.04
    steps:
    
      # Step 1: Check out the code
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Python (skip requirements installation for now)
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # Step 3: Install necessary dependencies (including Chrome and Chromium)
      - name: Install necessary dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            wget \
            curl \
            unzip \
            python3-pip \
            chromium-browser \
            libgconf-2-4 \
            libnss3 \
            libxss1 \
            libappindicator3-1 \
            libasound2

      # Step 4: Install Selenium using pip
      - name: Install Selenium
        run: |
          pip install selenium

      # Step 5: Get the installed Chrome version
      - name: Get installed Chrome version
        id: chrome_version
        run: |
          CHROME_VERSION=$(google-chrome --version | awk '{print $3}')
          echo "Installed Chrome version is $CHROME_VERSION"
          echo "::set-output name=chrome_version::$CHROME_VERSION"

      # Step 6: Download and install the matching ChromeDriver
      - name: Install ChromeDriver
        run: |
          CHROME_VERSION=${{ steps.chrome_version.outputs.chrome_version }}
          DRIVER_URL="https://chromedriver.storage.googleapis.com/$CHROME_VERSION/chromedriver_linux64.zip"
          echo "Downloading ChromeDriver for version $CHROME_VERSION"
          
          # Download and install the correct ChromeDriver
          wget "$DRIVER_URL" -O chromedriver-linux64.zip
          unzip chromedriver-linux64.zip
          sudo mv chromedriver /usr/local/bin/chromedriver
          sudo chmod +x /usr/local/bin/chromedriver

      # Step 7: Run the crawler script (make sure your script is in the correct location)
      - name: Run Selenium crawler
        run: |
          python3 crawler.py

      # Step 8: Upload the results (if you have any result files to upload)
      - name: Upload crawled PDFs as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: crawled-pdfs
          path: pdf_results/
