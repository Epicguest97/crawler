name: Selenium Crawler

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  selenium-crawl:
    runs-on: ubuntu-22.04
    steps:
    
      # Step 1: Check out the code
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            wget \
            curl \
            unzip \
            python3-pip \
            libgconf-2-4 \
            chromium-browser
          pip install -r requirements.txt

      # Step 4: Install Chrome for Testing and matching ChromeDriver
      - name: Install Chrome for Testing and matching ChromeDriver
        run: |
          # Get the installed Chrome version
          CHROME_VERSION=$(google-chrome --version | awk '{print $3}')
          
          # Fetch the ChromeDriver URL that matches the installed Chrome version
          DRIVER_URL="https://chromedriver.storage.googleapis.com/$CHROME_VERSION/chromedriver_linux64.zip"
  
          # Download and install ChromeDriver
          echo "Installing ChromeDriver for Chrome version $CHROME_VERSION"
          
          wget "$DRIVER_URL" -O chromedriver-linux64.zip
          unzip chromedriver-linux64.zip
          sudo mv chromedriver /usr/local/bin/chromedriver
          sudo chmod +x /usr/local/bin/chromedriver

      # Step 5: Run the crawler script
      - name: Run Selenium crawler
        run: |
          python3 crawler.py

      # Step 6: Upload results as an artifact
      - name: Upload PDFs as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: crawled-pdfs
          path: pdf_results/
